{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9ea8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tirex import load_model, ForecastModel\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.data_loader import create_cached_tsmixup_datasets\n",
    "import time\n",
    "\n",
    "# from utils.utils import load_test_data\n",
    "context_len = 512\n",
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7af2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CREATING CACHED TSMIXUP DATASETS\n",
      "==================================================\n",
      "üìÇ Found existing processed data at /extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/tsmixup_processed_300000_512_128.pkl\n",
      "‚ö° Loading preprocessed data from cache...\n",
      "‚úÖ Loaded 172,454 preprocessed samples\n",
      "üìÖ Cache created: 2025-08-22 13:11:48\n",
      "\n",
      "üìä DATASET SUMMARY:\n",
      "  Total processed samples: 172,454\n",
      "  Context length: 512\n",
      "  Prediction length: 128\n",
      "üîÄ Shuffling data...\n",
      "üìà Data split:\n",
      "  Training samples: 155,208\n",
      "  Validation samples: 17,246\n",
      "  Train ratio: 90.0%\n",
      "üèóÔ∏è  Creating PyTorch datasets...\n",
      "üèóÔ∏è  Dataset created with 155,208 samples\n",
      "üìä Augmentation: ON\n",
      "üìà Dataset Statistics (from 1000 samples):\n",
      "  Sequence lengths: min=640, max=2046, mean=1318\n",
      "  Value ranges: min=-48.3022, max=72.0737\n",
      "  Value stats: mean=0.8625, std=2.7795\n",
      "üèóÔ∏è  Dataset created with 17,246 samples\n",
      "üìä Augmentation: OFF\n",
      "üìà Dataset Statistics (from 1000 samples):\n",
      "  Sequence lengths: min=640, max=2047, mean=1307\n",
      "  Value ranges: min=-17.3232, max=473.9922\n",
      "  Value stats: mean=0.9819, std=2.3620\n",
      "\n",
      "üéâ DATASETS CREATED SUCCESSFULLY!\n",
      "‚úÖ Train dataset: 155,208 samples\n",
      "‚úÖ Validation dataset: 17,246 samples\n",
      "\n",
      "üß™ Testing dataset loading...\n",
      "‚úÖ Sample shapes:\n",
      "  Train - Past: torch.Size([512]), Future: torch.Size([128])\n",
      "  Val   - Past: torch.Size([512]), Future: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Loading tsmixup dataset\n",
    "train_dataset, val_dataset = create_cached_tsmixup_datasets(\n",
    "        max_samples=300000,\n",
    "        context_length=512,\n",
    "        prediction_length=128, # 1 or 128\n",
    "        num_workers=16,\n",
    "        cache_dir=\"/extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/\",\n",
    "        processed_cache_path=\"/extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/tsmixup_processed_300000_512_128.pkl\",\n",
    "        batch_size=4000\n",
    "    )\n",
    "\n",
    "def load_dataset(dataset, ts=1000, pred_length=1, ctx_len=512):\n",
    "    if dataset == 'tsmixup':\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(ts) if isinstance(ts, int) else ts:\n",
    "            val_dict = val_dataset[i]\n",
    "            x.append(val_dict['past_values'])\n",
    "            y.append(val_dict['future_values'])\n",
    "        x = torch.stack(x)[:, -ctx_len:]\n",
    "        y = torch.stack(y)[:,:pred_length]\n",
    "        \n",
    "    else:\n",
    "        dataset_path = f\"/extra/datalab_scratch0/ctadler/time_series_models/ts_foundation_calibration/data/{dataset}/y_{dataset}.csv\"\n",
    "        timestamp_column = \"ds\"\n",
    "\n",
    "        data = pd.read_csv(\n",
    "            dataset_path,\n",
    "            parse_dates=[timestamp_column],\n",
    "            index_col=0\n",
    "        )\n",
    "\n",
    "        x = []\n",
    "        for id, vals in data.groupby('unique_id'):\n",
    "            x.append(torch.from_numpy(vals['y'].to_numpy(np.float32)))\n",
    "        x = torch.stack(x)\n",
    "\n",
    "    if dataset != 'tsmixup':\n",
    "        y = x[:,ctx_len:ctx_len+pred_length]\n",
    "        x = x[:,:ctx_len]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f48ee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctadler/.conda/envs/tirex/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:543: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n",
      "/home/ctadler/.conda/envs/tirex/lib/python3.11/site-packages/xlstm/blocks/slstm/cell.py:568: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @conditional_decorator(\n"
     ]
    }
   ],
   "source": [
    "model: ForecastModel = load_model(\"NX-AI/TiRex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e21745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.552509\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "x, y = load_dataset(\"tsmixup\", batch_size)\n",
    "pred_len = 128\n",
    "context_len = 512\n",
    "x_input = x[:batch_size, -context_len:]\n",
    "d_model = model.model_config.block_kwargs.embedding_dim\n",
    "patch_size = model.model_config.output_patch_size\n",
    "\n",
    "out_patches = pred_len // patch_size\n",
    "decoder_out = torch.zeros(batch_size, out_patches, d_model)\n",
    "loc_scale = torch.zeros((batch_size, 2))\n",
    "start_time = time.time()\n",
    "forecast = model.forecast(context=x_input, prediction_length=pred_len, batch_size=batch_size,\n",
    "                                     max_accelerated_rollout_steps=4, \n",
    "                                     get_loc_scale=loc_scale,\n",
    "                                     get_hidden_states=decoder_out)\n",
    "print(f\"Time taken: {(time.time()-start_time):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu torch.Size([1024, 128])\n",
      "torch.Size([1024, 4, 512]) torch.Size([1024, 2])\n"
     ]
    }
   ],
   "source": [
    "print(forecast[0].shape, forecast[1].shape)\n",
    "# print(loc_scale[:5,:])\n",
    "print(decoder_out.shape, loc_scale.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "977cd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "import einops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tirex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
