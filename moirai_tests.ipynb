{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88dd707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.model.moirai2 import Moirai2Forecast, Moirai2Module\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions import (Normal, StudentT, Poisson)\n",
    "from uni2ts.distribution.negative_binomial import (NegativeBinomial)\n",
    "from uni2ts.distribution import (MixtureOutput, \n",
    "                                 NormalOutput, \n",
    "                                 StudentTOutput,\n",
    "                                LaplaceOutput, \n",
    "                                NormalFixedScaleOutput,\n",
    "                                NegativeBinomialOutput, \n",
    "                                LogNormalOutput)\n",
    "from utils.data_loader import create_cached_tsmixup_datasets\n",
    "from load_cached_features import *\n",
    "from timesfm.pytorch_patched_decoder import ResidualBlock\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.special import stdtrit\n",
    "from scipy.stats import (poisson, nbinom)\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "\n",
    "from collections.abc import Generator\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "import einops\n",
    "# from utils.utils import load_test_data\n",
    "context_len = 512\n",
    "device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5852a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading tsmixup dataset\n",
    "train_dataset, val_dataset = create_cached_tsmixup_datasets(\n",
    "        max_samples=300000,\n",
    "        context_length=512,\n",
    "        prediction_length=128, # 1 or 128\n",
    "        num_workers=16,\n",
    "        cache_dir=\"/extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/\",\n",
    "        processed_cache_path=\"/extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/tsmixup_processed_300000_512_128.pkl\",\n",
    "        batch_size=4000\n",
    "    )\n",
    "\n",
    "def load_dataset(dataset, ts=1000, pred_length=1, ctx_len=512):\n",
    "    if dataset == 'tsmixup':\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(ts) if isinstance(ts, int) else ts:\n",
    "            val_dict = val_dataset[i]\n",
    "            x.append(val_dict['past_values'])\n",
    "            y.append(val_dict['future_values'])\n",
    "        x = torch.stack(x)[:, -ctx_len:]\n",
    "        y = torch.stack(y)[:,:pred_length]\n",
    "        \n",
    "    else:\n",
    "        dataset_path = f\"/extra/datalab_scratch0/ctadler/time_series_models/ts_foundation_calibration/data/{dataset}/y_{dataset}.csv\"\n",
    "        timestamp_column = \"ds\"\n",
    "\n",
    "        data = pd.read_csv(\n",
    "            dataset_path,\n",
    "            parse_dates=[timestamp_column],\n",
    "            index_col=0\n",
    "        )\n",
    "\n",
    "        x = []\n",
    "        for id, vals in data.groupby('unique_id'):\n",
    "            x.append(torch.from_numpy(vals['y'].to_numpy(np.float32)))\n",
    "        x = torch.stack(x)\n",
    "\n",
    "    if dataset != 'tsmixup':\n",
    "        y = x[:,ctx_len:ctx_len+pred_length]\n",
    "        x = x[:,:ctx_len]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8b4d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "pred_len = 64\n",
    "patch_size = 32  # patch size: choose from {\"auto\", 8, 16, 32, 64, 128}\n",
    "moirai = MoiraiForecast(\n",
    "        module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\"),\n",
    "        prediction_length=pred_len,\n",
    "        context_length=context_len,\n",
    "        patch_size=patch_size,\n",
    "        num_samples=100,\n",
    "        target_dim=1,\n",
    "        feat_dynamic_real_dim=0,\n",
    "        past_feat_dynamic_real_dim=0,\n",
    "    )\n",
    "\n",
    "patch_size = 16  # patch size: choose from {\"auto\", 8, 16, 32, 64, 128}\n",
    "moirai = Moirai2Forecast(\n",
    "        module=Moirai2Module.from_pretrained(\n",
    "            f\"Salesforce/moirai-2.0-R-small\",\n",
    "        ),\n",
    "        prediction_length=pred_len,\n",
    "        context_length=context_len,\n",
    "        target_dim=1,\n",
    "        feat_dynamic_real_dim=0,\n",
    "        past_feat_dynamic_real_dim=0,\n",
    "    )\n",
    "print(moirai.module.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b77c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 36, 576])\n",
      "tensor([[[-4.2389e-01, -2.1102e-01, -5.2238e-02,  ...,  3.3228e-01,\n",
      "           3.7784e-01,  4.2304e-01],\n",
      "         [ 4.0230e-01,  2.8132e-01,  8.4823e-02,  ..., -9.2818e-01,\n",
      "          -1.2928e-01,  2.1589e-01],\n",
      "         [ 4.7088e-01,  8.1729e-01,  9.4729e-01,  ...,  1.2616e+00,\n",
      "           1.2408e+00,  1.1349e+00],\n",
      "         ...,\n",
      "         [ 3.3687e+00,  3.4486e+00,  3.5951e+00,  ...,  3.5238e+00,\n",
      "           3.3352e+00,  3.1638e+00],\n",
      "         [ 2.9093e+00,  2.6798e+00,  2.8039e+00,  ...,  4.0414e+00,\n",
      "           4.2295e+00,  4.2987e+00],\n",
      "         [ 4.3955e+00,  4.4018e+00,  4.3972e+00,  ...,  3.8909e+00,\n",
      "           3.6451e+00,  3.4308e+00]],\n",
      "\n",
      "        [[-4.5164e-02, -4.3477e-02, -4.4172e-02,  ..., -2.2126e-02,\n",
      "          -1.7004e-02, -2.1506e-02],\n",
      "         [-3.4099e-02, -2.4940e-02, -1.8077e-02,  ...,  1.0282e-01,\n",
      "          -9.6476e-03, -1.7290e-02],\n",
      "         [-2.3975e-02, -3.1502e-02, -3.2562e-02,  ..., -2.2143e-02,\n",
      "          -3.6243e-02, -2.0800e-02],\n",
      "         ...,\n",
      "         [ 1.7674e-01,  1.5322e-01,  1.3487e-01,  ...,  3.6639e-01,\n",
      "           6.9415e-01,  9.6217e-01],\n",
      "         [ 1.1690e+00,  1.5507e+00,  6.9119e-01,  ...,  3.1023e-01,\n",
      "           2.6859e-01,  2.3933e-01],\n",
      "         [ 2.0107e-01,  1.7357e-01,  1.7060e-01,  ...,  1.1931e+00,\n",
      "           1.4360e+00,  1.8661e+00]],\n",
      "\n",
      "        [[-6.3681e-03, -3.0767e-02, -2.9324e-02,  ...,  3.1509e-01,\n",
      "           2.9724e-01,  4.3645e-01],\n",
      "         [ 6.6556e-01,  1.1508e+00,  1.2942e+00,  ...,  7.2969e-01,\n",
      "           1.5019e-02, -2.1630e-03],\n",
      "         [ 3.7509e-04, -2.7317e-03,  1.6754e-02,  ...,  6.5810e-01,\n",
      "           9.4040e-01,  1.5177e+00],\n",
      "         ...,\n",
      "         [ 8.0995e-01,  1.2657e+00,  1.3751e+00,  ...,  3.1075e+00,\n",
      "           2.5609e+00,  2.2146e+00],\n",
      "         [ 2.0616e+00,  1.8711e+00,  4.6848e-01,  ...,  6.2720e-01,\n",
      "           9.0467e-01,  1.3731e+00],\n",
      "         [ 1.5015e+00,  1.6881e+00,  2.0307e+00,  ...,  2.3830e+00,\n",
      "           2.2247e+00,  2.0309e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3013e-02, -7.3841e-03, -1.0972e-02,  ..., -1.0674e-02,\n",
      "          -8.4942e-03, -6.9435e-03],\n",
      "         [-7.6360e-03, -9.4060e-03, -1.6574e-02,  ..., -1.8444e-02,\n",
      "          -3.0580e-03, -4.2737e-04],\n",
      "         [-3.2427e-03, -5.0188e-03, -6.2948e-03,  ..., -5.6840e-03,\n",
      "          -8.1342e-03, -7.4639e-03],\n",
      "         ...,\n",
      "         [ 9.2072e-01,  8.9102e-01,  8.6737e-01,  ...,  7.7738e-01,\n",
      "           7.3070e-01,  7.2288e-01],\n",
      "         [ 7.1160e-01,  7.5979e-01,  1.5705e+00,  ...,  1.4745e+00,\n",
      "           1.4152e+00,  1.3656e+00],\n",
      "         [ 1.3297e+00,  1.2689e+00,  1.1927e+00,  ...,  1.1320e+00,\n",
      "           1.1211e+00,  1.1825e+00]],\n",
      "\n",
      "        [[-2.7772e-02, -1.7262e-02, -1.3827e-02,  ..., -2.2390e-03,\n",
      "          -1.5189e-02, -9.0474e-03],\n",
      "         [-3.0132e-02, -5.9801e-02, -6.4559e-02,  ..., -1.4837e-02,\n",
      "          -3.2257e-02, -1.8033e-02],\n",
      "         [-1.0249e-02, -1.8107e-03,  1.2513e-02,  ...,  7.2662e-02,\n",
      "           5.6966e-02,  3.3090e-02],\n",
      "         ...,\n",
      "         [ 1.5341e+00,  1.7182e+00,  1.7598e+00,  ...,  1.6350e+00,\n",
      "           1.4238e+00,  1.1912e+00],\n",
      "         [ 1.0413e+00,  8.9410e-01,  7.1112e-01,  ...,  1.6547e+00,\n",
      "           1.8466e+00,  2.0305e+00],\n",
      "         [ 2.0677e+00,  2.0927e+00,  2.0491e+00,  ...,  1.5207e+00,\n",
      "           1.3485e+00,  1.1743e+00]],\n",
      "\n",
      "        [[-1.8876e-02, -2.1523e-02, -2.6086e-02,  ..., -2.2674e-02,\n",
      "          -2.3624e-02, -2.1199e-02],\n",
      "         [-2.4417e-02, -1.8887e-02, -2.3261e-02,  ..., -2.0504e-02,\n",
      "          -1.2043e-02, -1.3157e-02],\n",
      "         [-1.6923e-02, -1.6279e-02, -1.7215e-02,  ..., -1.3157e-02,\n",
      "          -1.6000e-02, -1.1697e-02],\n",
      "         ...,\n",
      "         [ 5.7698e-02,  6.3940e-02,  7.1447e-02,  ...,  7.6534e-02,\n",
      "           8.2271e-02,  8.8541e-02],\n",
      "         [ 8.8675e-02,  9.0496e-02,  3.2798e-01,  ...,  3.7009e-01,\n",
      "           3.7819e-01,  3.8893e-01],\n",
      "         [ 3.9511e-01,  4.0595e-01,  4.0942e-01,  ...,  4.1018e-01,\n",
      "           4.1049e-01,  4.1367e-01]]], device='cuda:3')\n"
     ]
    }
   ],
   "source": [
    "x, y = load_dataset('tsmixup', len(val_dataset), pred_length=pred_len, ctx_len=context_len)\n",
    "batch_size = 32\n",
    "\n",
    "past_target = x[:batch_size, :, None].to(device)\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    target, observed_mask, sample_id, time_id, variate_id, prediction_mask = moirai._convert(\n",
    "        patch_size=patch_size,\n",
    "        past_target=past_target,                                 # B x past_time x D\n",
    "        past_observed_target=torch.isfinite(past_target),               # B x past_time x D (bool)\n",
    "        past_is_pad=torch.full_like(past_target[:, :, 0], False, dtype=bool),                                 # B x past_time (bool)\n",
    "    )\n",
    "    # patch_sizes = torch.ones_like(time_id, dtype=torch.long) * patch_size\n",
    "\n",
    "    moirai_module = moirai.module.to(device)\n",
    "    # moirai_module.get_reprs = True\n",
    "    # print(f\"Target: {target.shape}, observed: {observed_mask.shape}\")\n",
    "    # (preds, stats) = moirai_module(\n",
    "    #     target,\n",
    "    #     observed_mask,\n",
    "    #     sample_id,\n",
    "    #     time_id,\n",
    "    #     variate_id,\n",
    "    #     prediction_mask)\n",
    "    # print(f\"Took {(time.time()-start_time):.3f} seconds or {(time.time()-start_time)/batch_size:.3e} sec/sample\")\n",
    "    # print(preds.shape, stats.shape)\n",
    "    # print(prediction_mask.shape)\n",
    "    # print(preds[prediction_mask].reshape([batch_size, -1, preds.shape[-1]]).shape, stats[prediction_mask].shape)\n",
    "\n",
    "    moirai_module.get_reprs = False\n",
    "    moirai_module.eval()\n",
    "    preds = moirai_module(\n",
    "        target=target,\n",
    "        observed_mask=observed_mask,\n",
    "        sample_id=sample_id,\n",
    "        time_id=time_id,\n",
    "        variate_id=variate_id,\n",
    "        prediction_mask=prediction_mask,\n",
    "        training_mode=False)\n",
    "    print(preds.shape)\n",
    "    forecast = einops.rearrange(preds[:,context_len//patch_size,:],\n",
    "                                \"B (pred_len quantiles) -> B pred_len quantiles\",\n",
    "                                quantiles = 9, pred_len = pred_len)\n",
    "\n",
    "    # print(preds[prediction_mask].reshape([batch_size, -1, preds.shape[-1]])[:,].shape)\n",
    "    # print(torch.all(preds[prediction_mask].reshape([batch_size, -1, preds.shape[-1]]) == preds[:,-8:]))\n",
    "    # print(preds.shape)\n",
    "    # print(patch_sizes.shape, patch_size)\n",
    "    # print(past_target.shape)\n",
    "    # print(prediction_mask[0])\n",
    "\n",
    "# batch_size 64 = 7.527e-03 sec/sample 360MiB\n",
    "# batch_size 256 = 8.334e-05 sec/sample\n",
    "# batch_size 8192 = 6.369e-05 sec/sample 5164MiB \n",
    "# batch_size 17246 = 6.340e-05 sec/sample 11040MiB\n",
    "# batch_size 32768 = 7.402e-05 sec/sample 20450MiB\n",
    "# batch_size 40000 = 7.124e-05 sec/sample 22350MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4b56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 64)\n"
     ]
    }
   ],
   "source": [
    "moirai_module.get_reprs = False\n",
    "def torch_ds_to_gluonts_listdataset(dataset) -> Generator[dict[str, Any]]:\n",
    "    def entries():\n",
    "        for i in range(len(dataset)):\n",
    "            val_dict = dataset[i]\n",
    "            x = torch.cat((val_dict['past_values'], val_dict['future_values']))\n",
    "            # past_vals, future_vals = dataset[i]\n",
    "            yield {\n",
    "                \"target\": x.numpy(),  # array of shape (time,)\n",
    "                \"start\": datetime(1970, 1, 1, 0, 0),\n",
    "                \"freq\": 'h',\n",
    "                \"item_id\": f\"item_{i}\",\n",
    "            }\n",
    "\n",
    "    return ListDataset(entries(), freq='h')\n",
    "gluonts_ds = torch_ds_to_gluonts_listdataset(val_dataset)\n",
    "\n",
    "# print(x.shape)\n",
    "batch_size = 64\n",
    "predictor = moirai.create_predictor(batch_size=batch_size)\n",
    "forecasts = predictor.predict(gluonts_ds)\n",
    "\n",
    "input_it = iter(x)\n",
    "label_it = iter(y)\n",
    "forecast_it = iter(forecasts)\n",
    "\n",
    "start_time = time.time()\n",
    "for i, (input, label, forecast) in enumerate(zip(input_it, label_it, forecast_it)):\n",
    "    # print(f\"{i} {(time.time()-start_time):.4f}\")\n",
    "    print(forecast.forecast_array.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7dcbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
