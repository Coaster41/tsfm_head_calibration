{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e0e12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.distributions import (Normal, StudentT, Poisson)\n",
    "from uni2ts.distribution.negative_binomial import (NegativeBinomial)\n",
    "from uni2ts.distribution import (MixtureOutput, \n",
    "                                 NormalOutput, \n",
    "                                 StudentTOutput,\n",
    "                                LaplaceOutput, \n",
    "                                NormalFixedScaleOutput,\n",
    "                                NegativeBinomialOutput, \n",
    "                                LogNormalOutput)\n",
    "from utils.data_loader import create_cached_tsmixup_datasets\n",
    "from load_cached_features import *\n",
    "from timesfm.pytorch_patched_decoder import ResidualBlock\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.special import stdtrit\n",
    "from scipy.stats import (poisson, nbinom)\n",
    "from pytorch_forecasting.metrics.quantile import QuantileLoss\n",
    "\n",
    "from collections.abc import Generator\n",
    "from typing import Any\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from gluonts.dataset.common import ListDataset\n",
    "# from utils.utils import load_test_data\n",
    "context_len = 512\n",
    "device = 'cuda:3'\n",
    "from chronos import ChronosBoltPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30cbcfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CREATING CACHED TSMIXUP DATASETS\n",
      "==================================================\n",
      "üìÇ Found existing processed data at /extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/tsmixup_processed_300000_512_128.pkl\n",
      "‚ö° Loading preprocessed data from cache...\n",
      "‚úÖ Loaded 172,454 preprocessed samples\n",
      "üìÖ Cache created: 2025-08-22 13:11:48\n",
      "\n",
      "üìä DATASET SUMMARY:\n",
      "  Total processed samples: 172,454\n",
      "  Context length: 512\n",
      "  Prediction length: 128\n",
      "üîÄ Shuffling data...\n",
      "üìà Data split:\n",
      "  Training samples: 155,208\n",
      "  Validation samples: 17,246\n",
      "  Train ratio: 90.0%\n",
      "üèóÔ∏è  Creating PyTorch datasets...\n",
      "üèóÔ∏è  Dataset created with 155,208 samples\n",
      "üìä Augmentation: ON\n",
      "üìà Dataset Statistics (from 1000 samples):\n",
      "  Sequence lengths: min=640, max=2046, mean=1318\n",
      "  Value ranges: min=-48.3022, max=72.0737\n",
      "  Value stats: mean=0.8625, std=2.7795\n",
      "üèóÔ∏è  Dataset created with 17,246 samples\n",
      "üìä Augmentation: OFF\n",
      "üìà Dataset Statistics (from 1000 samples):\n",
      "  Sequence lengths: min=640, max=2047, mean=1307\n",
      "  Value ranges: min=-17.3232, max=473.9922\n",
      "  Value stats: mean=0.9819, std=2.3620\n",
      "\n",
      "üéâ DATASETS CREATED SUCCESSFULLY!\n",
      "‚úÖ Train dataset: 155,208 samples\n",
      "‚úÖ Validation dataset: 17,246 samples\n",
      "\n",
      "üß™ Testing dataset loading...\n",
      "‚úÖ Sample shapes:\n",
      "  Train - Past: torch.Size([512]), Future: torch.Size([128])\n",
      "  Val   - Past: torch.Size([512]), Future: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Loading tsmixup dataset\n",
    "train_dataset, val_dataset = create_cached_tsmixup_datasets(\n",
    "        max_samples=300000,\n",
    "        context_length=512,\n",
    "        prediction_length=128, # 1 or 128\n",
    "        num_workers=16,\n",
    "        cache_dir=\"/extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/\",\n",
    "        processed_cache_path=\"/extra/datalab_scratch0/ctadler/time_series_models/mechanistic_interpretability/data/tsmixup_cache/tsmixup_processed_300000_512_128.pkl\",\n",
    "        batch_size=4000\n",
    "    )\n",
    "\n",
    "def load_dataset(dataset, ts=1000, pred_length=1, ctx_len=512):\n",
    "    if dataset == 'tsmixup':\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(ts) if isinstance(ts, int) else ts:\n",
    "            val_dict = val_dataset[i]\n",
    "            x.append(val_dict['past_values'])\n",
    "            y.append(val_dict['future_values'])\n",
    "        x = torch.stack(x)[:, -ctx_len:]\n",
    "        y = torch.stack(y)[:,:pred_length]\n",
    "        \n",
    "    else:\n",
    "        dataset_path = f\"/extra/datalab_scratch0/ctadler/time_series_models/ts_foundation_calibration/data/{dataset}/y_{dataset}.csv\"\n",
    "        timestamp_column = \"ds\"\n",
    "\n",
    "        data = pd.read_csv(\n",
    "            dataset_path,\n",
    "            parse_dates=[timestamp_column],\n",
    "            index_col=0\n",
    "        )\n",
    "\n",
    "        x = []\n",
    "        for id, vals in data.groupby('unique_id'):\n",
    "            x.append(torch.from_numpy(vals['y'].to_numpy(np.float32)))\n",
    "        x = torch.stack(x)\n",
    "\n",
    "    if dataset != 'tsmixup':\n",
    "        y = x[:,ctx_len:ctx_len+pred_length]\n",
    "        x = x[:,:ctx_len]\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6095c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ChronosBoltPipeline.from_pretrained(\n",
    "        \"amazon/chronos-bolt-base\",\n",
    "        device_map=device,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "323d349d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.282304\n"
     ]
    }
   ],
   "source": [
    "x, y = load_dataset(\"tsmixup\", 1024)\n",
    "batch_size = 1024\n",
    "pred_len = 64\n",
    "context_len = 512\n",
    "x_input = x[:batch_size, -context_len:].to(device)\n",
    "d_model = pipeline.model.model_dim\n",
    "\n",
    "decoder_out = torch.zeros(batch_size, d_model)\n",
    "loc_scale = torch.zeros(batch_size, 2)\n",
    "\n",
    "def save_decoder_hook(module, input, output):\n",
    "    decoder_out[:] = output.last_hidden_state.squeeze().detach().cpu()\n",
    "    \n",
    "def save_encoder_hook(module, input, output):\n",
    "    loc_scale[:] = torch.stack(output[1], dim=-1).squeeze().detach().cpu()\n",
    "\n",
    "pipeline.model.decoder.register_forward_hook(save_decoder_hook)\n",
    "pipeline.model.instance_norm.register_forward_hook(save_encoder_hook)\n",
    "start_time = time.time()\n",
    "out = pipeline.model(x_input)\n",
    "print(f\"Time taken: {(time.time()-start_time):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f7afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 768]) torch.Size([1024, 2])\n",
      "torch.Size([1024, 9, 64])\n"
     ]
    }
   ],
   "source": [
    "print(decoder_out.shape, loc_scale.shape)\n",
    "print(out.quantile_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7556790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((10,2))\n",
    "print(x.device)\n",
    "x = x.to(device)\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6e4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
